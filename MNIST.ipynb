{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDxFx8seaA6N"
      },
      "source": [
        "Aim: Develop a CNN model to classify images using and without using dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "llbM-dI-aA6O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GZxIWjLWaA6P"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('mnist_train_small.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Y62pP0aA6P",
        "outputId": "5799d3ae-135a-49b7-b9c3-79ee6706fea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20000, 785)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D0egr3noaA6Q"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "batch_size = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ3fOq6AaA6Q",
        "outputId": "9bc60564-2841-46f9-ce83-7fd1def486e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K5noNNN3aA6Q"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = train.values[:, 1:], train.values[:, 0]\n",
        "y_train = F.one_hot(torch.tensor(y_train)).to(dtype=torch.float32, device=device)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32, device=device) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp-hfNCXaA6Q",
        "outputId": "73cea7b1-4a0d-42a2-d0d8-0680875574bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([20000, 784]), torch.Size([20000, 10]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4WyoMxMcaA6R"
      },
      "outputs": [],
      "source": [
        "class ANN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.l1 = nn.Linear(28 * 28, 512)\n",
        "        self.l2 = nn.Linear(512, 256)\n",
        "        self.l3 = nn.Linear(256, 128)\n",
        "        self.l4 = nn.Linear(128, 64)\n",
        "        self.l5 = nn.Linear(64, 32)\n",
        "        self.l6 = nn.Linear(32, 10)\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.l1(x))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.relu(self.l2(out))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.relu(self.l3(out))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.relu(self.l4(out))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.relu(self.l5(out))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.softmax(self.l6(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh1OiuMkaA6R",
        "outputId": "bcdb05f6-d101-4e2b-9695-e6c31d425301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANN(\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=-1)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (l1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (l2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (l3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (l4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (l5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (l6): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = ANN().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qJpszn9daA6R"
      },
      "outputs": [],
      "source": [
        "# Using cross entropy loss\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X6qgYocaaA6R",
        "outputId": "91ad53aa-c8eb-49f1-e2d2-1ed358a9b438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/500, Training Loss: 2.3018, Validation Loss: 2.3014\n",
            "Epoch: 2/500, Training Loss: 2.2997, Validation Loss: 2.2993\n",
            "Epoch: 3/500, Training Loss: 2.2922, Validation Loss: 2.2918\n",
            "Epoch: 4/500, Training Loss: 2.2586, Validation Loss: 2.2530\n",
            "Epoch: 5/500, Training Loss: 2.1918, Validation Loss: 2.1948\n",
            "Epoch: 6/500, Training Loss: 2.1390, Validation Loss: 2.1520\n",
            "Epoch: 7/500, Training Loss: 2.0956, Validation Loss: 2.0985\n",
            "Epoch: 8/500, Training Loss: 2.0409, Validation Loss: 2.0477\n",
            "Epoch: 9/500, Training Loss: 1.9972, Validation Loss: 2.0016\n",
            "Epoch: 10/500, Training Loss: 1.9637, Validation Loss: 1.9684\n",
            "Epoch: 11/500, Training Loss: 1.9182, Validation Loss: 1.9211\n",
            "Epoch: 12/500, Training Loss: 1.8784, Validation Loss: 1.8741\n",
            "Epoch: 13/500, Training Loss: 1.8419, Validation Loss: 1.8452\n",
            "Epoch: 14/500, Training Loss: 1.8078, Validation Loss: 1.8219\n",
            "Epoch: 15/500, Training Loss: 1.8019, Validation Loss: 1.8083\n",
            "Epoch: 16/500, Training Loss: 1.7815, Validation Loss: 1.7902\n",
            "Epoch: 17/500, Training Loss: 1.7621, Validation Loss: 1.7765\n",
            "Epoch: 18/500, Training Loss: 1.7628, Validation Loss: 1.7686\n",
            "Epoch: 19/500, Training Loss: 1.7507, Validation Loss: 1.7725\n",
            "Epoch: 20/500, Training Loss: 1.7484, Validation Loss: 1.7546\n",
            "Epoch: 21/500, Training Loss: 1.7416, Validation Loss: 1.7459\n",
            "Epoch: 22/500, Training Loss: 1.7288, Validation Loss: 1.7478\n",
            "Epoch: 23/500, Training Loss: 1.7324, Validation Loss: 1.7405\n",
            "Epoch: 24/500, Training Loss: 1.7249, Validation Loss: 1.7373\n",
            "Epoch: 25/500, Training Loss: 1.7291, Validation Loss: 1.7306\n",
            "Epoch: 26/500, Training Loss: 1.7250, Validation Loss: 1.7328\n",
            "Epoch: 27/500, Training Loss: 1.7183, Validation Loss: 1.7283\n",
            "Epoch: 28/500, Training Loss: 1.7186, Validation Loss: 1.7255\n",
            "Epoch: 29/500, Training Loss: 1.7130, Validation Loss: 1.7242\n",
            "Epoch: 30/500, Training Loss: 1.7092, Validation Loss: 1.7231\n",
            "Epoch: 31/500, Training Loss: 1.7078, Validation Loss: 1.7158\n",
            "Epoch: 32/500, Training Loss: 1.7113, Validation Loss: 1.7135\n",
            "Epoch: 33/500, Training Loss: 1.7034, Validation Loss: 1.7185\n",
            "Epoch: 34/500, Training Loss: 1.7019, Validation Loss: 1.7127\n",
            "Epoch: 35/500, Training Loss: 1.6974, Validation Loss: 1.7125\n",
            "Epoch: 36/500, Training Loss: 1.6977, Validation Loss: 1.7156\n",
            "Epoch: 37/500, Training Loss: 1.7073, Validation Loss: 1.7095\n",
            "Epoch: 38/500, Training Loss: 1.6987, Validation Loss: 1.7065\n",
            "Epoch: 39/500, Training Loss: 1.6958, Validation Loss: 1.7070\n",
            "Epoch: 40/500, Training Loss: 1.7003, Validation Loss: 1.7088\n",
            "Epoch: 41/500, Training Loss: 1.6985, Validation Loss: 1.7055\n",
            "Epoch: 42/500, Training Loss: 1.6964, Validation Loss: 1.7050\n",
            "Epoch: 43/500, Training Loss: 1.6895, Validation Loss: 1.7018\n",
            "Epoch: 44/500, Training Loss: 1.6896, Validation Loss: 1.6965\n",
            "Epoch: 45/500, Training Loss: 1.6974, Validation Loss: 1.6983\n",
            "Epoch: 46/500, Training Loss: 1.6775, Validation Loss: 1.6996\n",
            "Epoch: 47/500, Training Loss: 1.6831, Validation Loss: 1.6919\n",
            "Epoch: 48/500, Training Loss: 1.6689, Validation Loss: 1.6867\n",
            "Epoch: 49/500, Training Loss: 1.6743, Validation Loss: 1.6856\n",
            "Epoch: 50/500, Training Loss: 1.6571, Validation Loss: 1.6808\n",
            "Epoch: 51/500, Training Loss: 1.6642, Validation Loss: 1.6801\n",
            "Epoch: 52/500, Training Loss: 1.6617, Validation Loss: 1.6800\n",
            "Epoch: 53/500, Training Loss: 1.6560, Validation Loss: 1.6711\n",
            "Epoch: 54/500, Training Loss: 1.6510, Validation Loss: 1.6675\n",
            "Epoch: 55/500, Training Loss: 1.6463, Validation Loss: 1.6683\n",
            "Epoch: 56/500, Training Loss: 1.6482, Validation Loss: 1.6625\n",
            "Epoch: 57/500, Training Loss: 1.6508, Validation Loss: 1.6554\n",
            "Epoch: 58/500, Training Loss: 1.6459, Validation Loss: 1.6547\n",
            "Epoch: 59/500, Training Loss: 1.6478, Validation Loss: 1.6594\n",
            "Epoch: 60/500, Training Loss: 1.6369, Validation Loss: 1.6539\n",
            "Epoch: 61/500, Training Loss: 1.6436, Validation Loss: 1.6478\n",
            "Epoch: 62/500, Training Loss: 1.6340, Validation Loss: 1.6525\n",
            "Epoch: 63/500, Training Loss: 1.6324, Validation Loss: 1.6496\n",
            "Epoch: 64/500, Training Loss: 1.6317, Validation Loss: 1.6480\n",
            "Epoch: 65/500, Training Loss: 1.6405, Validation Loss: 1.6456\n",
            "Epoch: 66/500, Training Loss: 1.6377, Validation Loss: 1.6392\n",
            "Epoch: 67/500, Training Loss: 1.6334, Validation Loss: 1.6433\n",
            "Epoch: 68/500, Training Loss: 1.6260, Validation Loss: 1.6467\n",
            "Epoch: 69/500, Training Loss: 1.6231, Validation Loss: 1.6449\n",
            "Epoch: 70/500, Training Loss: 1.6276, Validation Loss: 1.6374\n",
            "Epoch: 71/500, Training Loss: 1.6237, Validation Loss: 1.6333\n",
            "Epoch: 72/500, Training Loss: 1.6240, Validation Loss: 1.6383\n",
            "Epoch: 73/500, Training Loss: 1.6203, Validation Loss: 1.6352\n",
            "Epoch: 74/500, Training Loss: 1.6209, Validation Loss: 1.6389\n",
            "Epoch: 75/500, Training Loss: 1.6255, Validation Loss: 1.6307\n",
            "Epoch: 76/500, Training Loss: 1.6197, Validation Loss: 1.6355\n",
            "Epoch: 77/500, Training Loss: 1.6122, Validation Loss: 1.6301\n",
            "Epoch: 78/500, Training Loss: 1.6083, Validation Loss: 1.6242\n",
            "Epoch: 79/500, Training Loss: 1.5906, Validation Loss: 1.6185\n",
            "Epoch: 80/500, Training Loss: 1.5943, Validation Loss: 1.6111\n",
            "Epoch: 81/500, Training Loss: 1.5761, Validation Loss: 1.6072\n",
            "Epoch: 82/500, Training Loss: 1.5686, Validation Loss: 1.5956\n",
            "Epoch: 83/500, Training Loss: 1.5743, Validation Loss: 1.6007\n",
            "Epoch: 84/500, Training Loss: 1.5614, Validation Loss: 1.5870\n",
            "Epoch: 85/500, Training Loss: 1.5614, Validation Loss: 1.5846\n",
            "Epoch: 86/500, Training Loss: 1.5429, Validation Loss: 1.5762\n",
            "Epoch: 87/500, Training Loss: 1.5505, Validation Loss: 1.5846\n",
            "Epoch: 88/500, Training Loss: 1.5384, Validation Loss: 1.5739\n",
            "Epoch: 89/500, Training Loss: 1.5436, Validation Loss: 1.5741\n",
            "Epoch: 90/500, Training Loss: 1.5360, Validation Loss: 1.5691\n",
            "Epoch: 91/500, Training Loss: 1.5390, Validation Loss: 1.5682\n",
            "Epoch: 92/500, Training Loss: 1.5361, Validation Loss: 1.5645\n",
            "Epoch: 93/500, Training Loss: 1.5358, Validation Loss: 1.5643\n",
            "Epoch: 94/500, Training Loss: 1.5356, Validation Loss: 1.5625\n",
            "Epoch: 95/500, Training Loss: 1.5241, Validation Loss: 1.5615\n",
            "Epoch: 96/500, Training Loss: 1.5301, Validation Loss: 1.5559\n",
            "Epoch: 97/500, Training Loss: 1.5268, Validation Loss: 1.5571\n",
            "Epoch: 98/500, Training Loss: 1.5310, Validation Loss: 1.5546\n",
            "Epoch: 99/500, Training Loss: 1.5280, Validation Loss: 1.5561\n",
            "Epoch: 100/500, Training Loss: 1.5265, Validation Loss: 1.5587\n",
            "Epoch: 101/500, Training Loss: 1.5271, Validation Loss: 1.5541\n",
            "Epoch: 102/500, Training Loss: 1.5194, Validation Loss: 1.5492\n",
            "Epoch: 103/500, Training Loss: 1.5219, Validation Loss: 1.5510\n",
            "Epoch: 104/500, Training Loss: 1.5192, Validation Loss: 1.5525\n",
            "Epoch: 105/500, Training Loss: 1.5183, Validation Loss: 1.5518\n",
            "Epoch: 106/500, Training Loss: 1.5175, Validation Loss: 1.5501\n",
            "Epoch: 107/500, Training Loss: 1.5147, Validation Loss: 1.5459\n",
            "Epoch: 108/500, Training Loss: 1.5158, Validation Loss: 1.5515\n",
            "Epoch: 109/500, Training Loss: 1.5093, Validation Loss: 1.5466\n",
            "Epoch: 110/500, Training Loss: 1.5081, Validation Loss: 1.5494\n",
            "Epoch: 111/500, Training Loss: 1.5132, Validation Loss: 1.5515\n",
            "Epoch: 112/500, Training Loss: 1.5066, Validation Loss: 1.5470\n",
            "Epoch: 113/500, Training Loss: 1.5075, Validation Loss: 1.5448\n",
            "Epoch: 114/500, Training Loss: 1.5067, Validation Loss: 1.5427\n",
            "Epoch: 115/500, Training Loss: 1.5045, Validation Loss: 1.5411\n",
            "Epoch: 116/500, Training Loss: 1.5024, Validation Loss: 1.5483\n",
            "Epoch: 117/500, Training Loss: 1.5012, Validation Loss: 1.5437\n",
            "Epoch: 118/500, Training Loss: 1.5041, Validation Loss: 1.5431\n",
            "Epoch: 119/500, Training Loss: 1.5012, Validation Loss: 1.5430\n",
            "Epoch: 120/500, Training Loss: 1.5052, Validation Loss: 1.5406\n",
            "Epoch: 121/500, Training Loss: 1.4981, Validation Loss: 1.5417\n",
            "Epoch: 122/500, Training Loss: 1.5031, Validation Loss: 1.5396\n",
            "Epoch: 123/500, Training Loss: 1.5042, Validation Loss: 1.5393\n",
            "Epoch: 124/500, Training Loss: 1.4937, Validation Loss: 1.5416\n",
            "Epoch: 125/500, Training Loss: 1.5023, Validation Loss: 1.5439\n",
            "Epoch: 126/500, Training Loss: 1.4982, Validation Loss: 1.5404\n",
            "Epoch: 127/500, Training Loss: 1.5008, Validation Loss: 1.5361\n",
            "Epoch: 128/500, Training Loss: 1.5032, Validation Loss: 1.5400\n",
            "Epoch: 129/500, Training Loss: 1.4976, Validation Loss: 1.5388\n",
            "Epoch: 130/500, Training Loss: 1.4957, Validation Loss: 1.5351\n",
            "Epoch: 131/500, Training Loss: 1.4963, Validation Loss: 1.5378\n",
            "Epoch: 132/500, Training Loss: 1.4950, Validation Loss: 1.5396\n",
            "Epoch: 133/500, Training Loss: 1.4969, Validation Loss: 1.5383\n",
            "Epoch: 134/500, Training Loss: 1.4912, Validation Loss: 1.5352\n",
            "Epoch: 135/500, Training Loss: 1.4954, Validation Loss: 1.5336\n",
            "Epoch: 136/500, Training Loss: 1.4966, Validation Loss: 1.5360\n",
            "Epoch: 137/500, Training Loss: 1.4921, Validation Loss: 1.5411\n",
            "Epoch: 138/500, Training Loss: 1.4984, Validation Loss: 1.5373\n",
            "Epoch: 139/500, Training Loss: 1.4877, Validation Loss: 1.5344\n",
            "Epoch: 140/500, Training Loss: 1.4907, Validation Loss: 1.5318\n",
            "Epoch: 141/500, Training Loss: 1.4945, Validation Loss: 1.5359\n",
            "Epoch: 142/500, Training Loss: 1.4923, Validation Loss: 1.5335\n",
            "Epoch: 143/500, Training Loss: 1.4868, Validation Loss: 1.5318\n",
            "Epoch: 144/500, Training Loss: 1.4894, Validation Loss: 1.5359\n",
            "Epoch: 145/500, Training Loss: 1.4907, Validation Loss: 1.5281\n",
            "Epoch: 146/500, Training Loss: 1.4908, Validation Loss: 1.5322\n",
            "Epoch: 147/500, Training Loss: 1.4889, Validation Loss: 1.5322\n",
            "Epoch: 148/500, Training Loss: 1.4868, Validation Loss: 1.5308\n",
            "Epoch: 149/500, Training Loss: 1.4863, Validation Loss: 1.5359\n",
            "Epoch: 150/500, Training Loss: 1.4907, Validation Loss: 1.5315\n",
            "Epoch: 151/500, Training Loss: 1.4863, Validation Loss: 1.5292\n",
            "Epoch: 152/500, Training Loss: 1.4856, Validation Loss: 1.5327\n",
            "Epoch: 153/500, Training Loss: 1.4850, Validation Loss: 1.5337\n",
            "Epoch: 154/500, Training Loss: 1.4853, Validation Loss: 1.5294\n",
            "Epoch: 155/500, Training Loss: 1.4864, Validation Loss: 1.5292\n",
            "Epoch: 156/500, Training Loss: 1.4866, Validation Loss: 1.5339\n",
            "Epoch: 157/500, Training Loss: 1.4835, Validation Loss: 1.5324\n",
            "Epoch: 158/500, Training Loss: 1.4825, Validation Loss: 1.5348\n",
            "Epoch: 159/500, Training Loss: 1.4852, Validation Loss: 1.5313\n",
            "Epoch: 160/500, Training Loss: 1.4826, Validation Loss: 1.5301\n",
            "Epoch: 161/500, Training Loss: 1.4839, Validation Loss: 1.5277\n",
            "Epoch: 162/500, Training Loss: 1.4779, Validation Loss: 1.5291\n",
            "Epoch: 163/500, Training Loss: 1.4833, Validation Loss: 1.5289\n",
            "Epoch: 164/500, Training Loss: 1.4807, Validation Loss: 1.5287\n",
            "Epoch: 165/500, Training Loss: 1.4796, Validation Loss: 1.5297\n",
            "Epoch: 166/500, Training Loss: 1.4847, Validation Loss: 1.5323\n",
            "Epoch: 167/500, Training Loss: 1.4807, Validation Loss: 1.5308\n",
            "Epoch: 168/500, Training Loss: 1.4831, Validation Loss: 1.5268\n",
            "Epoch: 169/500, Training Loss: 1.4778, Validation Loss: 1.5281\n",
            "Epoch: 170/500, Training Loss: 1.4801, Validation Loss: 1.5253\n",
            "Epoch: 171/500, Training Loss: 1.4791, Validation Loss: 1.5251\n",
            "Epoch: 172/500, Training Loss: 1.4797, Validation Loss: 1.5290\n",
            "Epoch: 173/500, Training Loss: 1.4813, Validation Loss: 1.5290\n",
            "Epoch: 174/500, Training Loss: 1.4771, Validation Loss: 1.5274\n",
            "Epoch: 175/500, Training Loss: 1.4773, Validation Loss: 1.5298\n",
            "Epoch: 176/500, Training Loss: 1.4804, Validation Loss: 1.5284\n",
            "Epoch: 177/500, Training Loss: 1.4774, Validation Loss: 1.5255\n",
            "Epoch: 178/500, Training Loss: 1.4797, Validation Loss: 1.5288\n",
            "Epoch: 179/500, Training Loss: 1.4791, Validation Loss: 1.5235\n",
            "Epoch: 180/500, Training Loss: 1.4802, Validation Loss: 1.5241\n",
            "Epoch: 181/500, Training Loss: 1.4770, Validation Loss: 1.5238\n",
            "Epoch: 182/500, Training Loss: 1.4753, Validation Loss: 1.5265\n",
            "Epoch: 183/500, Training Loss: 1.4768, Validation Loss: 1.5218\n",
            "Epoch: 184/500, Training Loss: 1.4743, Validation Loss: 1.5257\n",
            "Epoch: 185/500, Training Loss: 1.4811, Validation Loss: 1.5267\n",
            "Epoch: 186/500, Training Loss: 1.4797, Validation Loss: 1.5239\n",
            "Epoch: 187/500, Training Loss: 1.4770, Validation Loss: 1.5258\n",
            "Epoch: 188/500, Training Loss: 1.4740, Validation Loss: 1.5232\n",
            "Epoch: 189/500, Training Loss: 1.4756, Validation Loss: 1.5245\n",
            "Epoch: 190/500, Training Loss: 1.4757, Validation Loss: 1.5243\n",
            "Epoch: 191/500, Training Loss: 1.4778, Validation Loss: 1.5241\n",
            "Epoch: 192/500, Training Loss: 1.4734, Validation Loss: 1.5232\n",
            "Epoch: 193/500, Training Loss: 1.4749, Validation Loss: 1.5214\n",
            "Epoch: 194/500, Training Loss: 1.4749, Validation Loss: 1.5263\n",
            "Epoch: 195/500, Training Loss: 1.4744, Validation Loss: 1.5208\n",
            "Epoch: 196/500, Training Loss: 1.4751, Validation Loss: 1.5222\n",
            "Epoch: 197/500, Training Loss: 1.4747, Validation Loss: 1.5204\n",
            "Epoch: 198/500, Training Loss: 1.4735, Validation Loss: 1.5236\n",
            "Epoch: 199/500, Training Loss: 1.4778, Validation Loss: 1.5232\n",
            "Epoch: 200/500, Training Loss: 1.4754, Validation Loss: 1.5212\n",
            "Epoch: 201/500, Training Loss: 1.4743, Validation Loss: 1.5216\n",
            "Epoch: 202/500, Training Loss: 1.4728, Validation Loss: 1.5217\n",
            "Epoch: 203/500, Training Loss: 1.4751, Validation Loss: 1.5239\n",
            "Epoch: 204/500, Training Loss: 1.4723, Validation Loss: 1.5199\n",
            "Epoch: 205/500, Training Loss: 1.4701, Validation Loss: 1.5249\n",
            "Epoch: 206/500, Training Loss: 1.4745, Validation Loss: 1.5247\n",
            "Epoch: 207/500, Training Loss: 1.4707, Validation Loss: 1.5184\n",
            "Epoch: 208/500, Training Loss: 1.4739, Validation Loss: 1.5218\n",
            "Epoch: 209/500, Training Loss: 1.4738, Validation Loss: 1.5208\n",
            "Epoch: 210/500, Training Loss: 1.4745, Validation Loss: 1.5147\n",
            "Epoch: 211/500, Training Loss: 1.4716, Validation Loss: 1.5202\n",
            "Epoch: 212/500, Training Loss: 1.4765, Validation Loss: 1.5220\n",
            "Epoch: 213/500, Training Loss: 1.4700, Validation Loss: 1.5238\n",
            "Epoch: 214/500, Training Loss: 1.4719, Validation Loss: 1.5230\n",
            "Epoch: 215/500, Training Loss: 1.4758, Validation Loss: 1.5233\n",
            "Epoch: 216/500, Training Loss: 1.4740, Validation Loss: 1.5205\n",
            "Epoch: 217/500, Training Loss: 1.4692, Validation Loss: 1.5194\n",
            "Epoch: 218/500, Training Loss: 1.4711, Validation Loss: 1.5214\n",
            "Epoch: 219/500, Training Loss: 1.4699, Validation Loss: 1.5199\n",
            "Epoch: 220/500, Training Loss: 1.4711, Validation Loss: 1.5175\n",
            "Epoch: 221/500, Training Loss: 1.4696, Validation Loss: 1.5212\n",
            "Epoch: 222/500, Training Loss: 1.4701, Validation Loss: 1.5222\n",
            "Epoch: 223/500, Training Loss: 1.4729, Validation Loss: 1.5205\n",
            "Epoch: 224/500, Training Loss: 1.4698, Validation Loss: 1.5195\n",
            "Epoch: 225/500, Training Loss: 1.4736, Validation Loss: 1.5199\n",
            "Epoch: 226/500, Training Loss: 1.4713, Validation Loss: 1.5200\n",
            "Epoch: 227/500, Training Loss: 1.4699, Validation Loss: 1.5216\n",
            "Epoch: 228/500, Training Loss: 1.4697, Validation Loss: 1.5169\n",
            "Epoch: 229/500, Training Loss: 1.4689, Validation Loss: 1.5166\n",
            "Epoch: 230/500, Training Loss: 1.4701, Validation Loss: 1.5184\n",
            "Epoch: 231/500, Training Loss: 1.4702, Validation Loss: 1.5194\n",
            "Epoch: 232/500, Training Loss: 1.4671, Validation Loss: 1.5193\n",
            "Epoch: 233/500, Training Loss: 1.4680, Validation Loss: 1.5156\n",
            "Epoch: 234/500, Training Loss: 1.4698, Validation Loss: 1.5177\n",
            "Epoch: 235/500, Training Loss: 1.4731, Validation Loss: 1.5173\n",
            "Epoch: 236/500, Training Loss: 1.4698, Validation Loss: 1.5165\n",
            "Epoch: 237/500, Training Loss: 1.4699, Validation Loss: 1.5167\n",
            "Epoch: 238/500, Training Loss: 1.4700, Validation Loss: 1.5182\n",
            "Epoch: 239/500, Training Loss: 1.4711, Validation Loss: 1.5189\n",
            "Epoch: 240/500, Training Loss: 1.4687, Validation Loss: 1.5177\n",
            "Epoch: 241/500, Training Loss: 1.4687, Validation Loss: 1.5160\n",
            "Epoch: 242/500, Training Loss: 1.4690, Validation Loss: 1.5182\n",
            "Epoch: 243/500, Training Loss: 1.4672, Validation Loss: 1.5205\n",
            "Epoch: 244/500, Training Loss: 1.4688, Validation Loss: 1.5186\n",
            "Epoch: 245/500, Training Loss: 1.4705, Validation Loss: 1.5161\n",
            "Epoch: 246/500, Training Loss: 1.4705, Validation Loss: 1.5161\n",
            "Epoch: 247/500, Training Loss: 1.4686, Validation Loss: 1.5160\n",
            "Epoch: 248/500, Training Loss: 1.4670, Validation Loss: 1.5142\n",
            "Epoch: 249/500, Training Loss: 1.4719, Validation Loss: 1.5163\n",
            "Epoch: 250/500, Training Loss: 1.4690, Validation Loss: 1.5168\n",
            "Epoch: 251/500, Training Loss: 1.4690, Validation Loss: 1.5152\n",
            "Epoch: 252/500, Training Loss: 1.4691, Validation Loss: 1.5198\n",
            "Epoch: 253/500, Training Loss: 1.4654, Validation Loss: 1.5168\n",
            "Epoch: 254/500, Training Loss: 1.4703, Validation Loss: 1.5157\n",
            "Epoch: 255/500, Training Loss: 1.4675, Validation Loss: 1.5123\n",
            "Epoch: 256/500, Training Loss: 1.4676, Validation Loss: 1.5141\n",
            "Epoch: 257/500, Training Loss: 1.4671, Validation Loss: 1.5152\n",
            "Epoch: 258/500, Training Loss: 1.4688, Validation Loss: 1.5178\n",
            "Epoch: 259/500, Training Loss: 1.4673, Validation Loss: 1.5166\n",
            "Epoch: 260/500, Training Loss: 1.4707, Validation Loss: 1.5151\n",
            "Epoch: 261/500, Training Loss: 1.4697, Validation Loss: 1.5158\n",
            "Epoch: 262/500, Training Loss: 1.4662, Validation Loss: 1.5179\n",
            "Epoch: 263/500, Training Loss: 1.4658, Validation Loss: 1.5126\n",
            "Epoch: 264/500, Training Loss: 1.4669, Validation Loss: 1.5140\n",
            "Epoch: 265/500, Training Loss: 1.4673, Validation Loss: 1.5185\n",
            "Epoch: 266/500, Training Loss: 1.4705, Validation Loss: 1.5172\n",
            "Epoch: 267/500, Training Loss: 1.4686, Validation Loss: 1.5168\n",
            "Epoch: 268/500, Training Loss: 1.4672, Validation Loss: 1.5133\n",
            "Epoch: 269/500, Training Loss: 1.4690, Validation Loss: 1.5164\n",
            "Epoch: 270/500, Training Loss: 1.4681, Validation Loss: 1.5147\n",
            "Epoch: 271/500, Training Loss: 1.4676, Validation Loss: 1.5152\n",
            "Epoch: 272/500, Training Loss: 1.4681, Validation Loss: 1.5158\n",
            "Epoch: 273/500, Training Loss: 1.4676, Validation Loss: 1.5175\n",
            "Epoch: 274/500, Training Loss: 1.4667, Validation Loss: 1.5169\n",
            "Epoch: 275/500, Training Loss: 1.4670, Validation Loss: 1.5117\n",
            "Epoch: 276/500, Training Loss: 1.4669, Validation Loss: 1.5120\n",
            "Epoch: 277/500, Training Loss: 1.4668, Validation Loss: 1.5163\n",
            "Epoch: 278/500, Training Loss: 1.4677, Validation Loss: 1.5137\n",
            "Epoch: 279/500, Training Loss: 1.4668, Validation Loss: 1.5124\n",
            "Epoch: 280/500, Training Loss: 1.4670, Validation Loss: 1.5126\n",
            "Epoch: 281/500, Training Loss: 1.4659, Validation Loss: 1.5150\n",
            "Epoch: 282/500, Training Loss: 1.4667, Validation Loss: 1.5138\n",
            "Epoch: 283/500, Training Loss: 1.4673, Validation Loss: 1.5144\n",
            "Epoch: 284/500, Training Loss: 1.4669, Validation Loss: 1.5163\n",
            "Epoch: 285/500, Training Loss: 1.4689, Validation Loss: 1.5136\n",
            "Epoch: 286/500, Training Loss: 1.4663, Validation Loss: 1.5116\n",
            "Epoch: 287/500, Training Loss: 1.4684, Validation Loss: 1.5133\n",
            "Epoch: 288/500, Training Loss: 1.4654, Validation Loss: 1.5146\n",
            "Epoch: 289/500, Training Loss: 1.4698, Validation Loss: 1.5153\n",
            "Epoch: 290/500, Training Loss: 1.4702, Validation Loss: 1.5143\n",
            "Epoch: 291/500, Training Loss: 1.4665, Validation Loss: 1.5147\n",
            "Epoch: 292/500, Training Loss: 1.4676, Validation Loss: 1.5114\n",
            "Epoch: 293/500, Training Loss: 1.4688, Validation Loss: 1.5178\n",
            "Epoch: 294/500, Training Loss: 1.4682, Validation Loss: 1.5118\n",
            "Epoch: 295/500, Training Loss: 1.4687, Validation Loss: 1.5085\n",
            "Epoch: 296/500, Training Loss: 1.4651, Validation Loss: 1.5125\n",
            "Epoch: 297/500, Training Loss: 1.4680, Validation Loss: 1.5132\n",
            "Epoch: 298/500, Training Loss: 1.4671, Validation Loss: 1.5109\n",
            "Epoch: 299/500, Training Loss: 1.4687, Validation Loss: 1.5133\n",
            "Epoch: 300/500, Training Loss: 1.4698, Validation Loss: 1.5123\n",
            "Epoch: 301/500, Training Loss: 1.4658, Validation Loss: 1.5138\n",
            "Epoch: 302/500, Training Loss: 1.4665, Validation Loss: 1.5140\n",
            "Epoch: 303/500, Training Loss: 1.4654, Validation Loss: 1.5175\n",
            "Epoch: 304/500, Training Loss: 1.4655, Validation Loss: 1.5125\n",
            "Epoch: 305/500, Training Loss: 1.4693, Validation Loss: 1.5119\n",
            "Epoch: 306/500, Training Loss: 1.4663, Validation Loss: 1.5111\n",
            "Epoch: 307/500, Training Loss: 1.4668, Validation Loss: 1.5126\n",
            "Epoch: 308/500, Training Loss: 1.4663, Validation Loss: 1.5124\n",
            "Epoch: 309/500, Training Loss: 1.4662, Validation Loss: 1.5135\n",
            "Epoch: 310/500, Training Loss: 1.4677, Validation Loss: 1.5098\n",
            "Epoch: 311/500, Training Loss: 1.4653, Validation Loss: 1.5095\n",
            "Epoch: 312/500, Training Loss: 1.4690, Validation Loss: 1.5101\n",
            "Epoch: 313/500, Training Loss: 1.4685, Validation Loss: 1.5134\n",
            "Epoch: 314/500, Training Loss: 1.4666, Validation Loss: 1.5103\n",
            "Epoch: 315/500, Training Loss: 1.4669, Validation Loss: 1.5141\n",
            "Epoch: 316/500, Training Loss: 1.4661, Validation Loss: 1.5115\n",
            "Epoch: 317/500, Training Loss: 1.4664, Validation Loss: 1.5151\n",
            "Epoch: 318/500, Training Loss: 1.4676, Validation Loss: 1.5100\n",
            "Epoch: 319/500, Training Loss: 1.4694, Validation Loss: 1.5125\n",
            "Epoch: 320/500, Training Loss: 1.4678, Validation Loss: 1.5150\n",
            "Epoch: 321/500, Training Loss: 1.4658, Validation Loss: 1.5127\n",
            "Epoch: 322/500, Training Loss: 1.4647, Validation Loss: 1.5137\n",
            "Epoch: 323/500, Training Loss: 1.4687, Validation Loss: 1.5095\n",
            "Epoch: 324/500, Training Loss: 1.4653, Validation Loss: 1.5118\n",
            "Epoch: 325/500, Training Loss: 1.4663, Validation Loss: 1.5115\n",
            "Epoch: 326/500, Training Loss: 1.4662, Validation Loss: 1.5093\n",
            "Epoch: 327/500, Training Loss: 1.4663, Validation Loss: 1.5084\n",
            "Epoch: 328/500, Training Loss: 1.4665, Validation Loss: 1.5116\n",
            "Epoch: 329/500, Training Loss: 1.4665, Validation Loss: 1.5142\n",
            "Epoch: 330/500, Training Loss: 1.4681, Validation Loss: 1.5098\n",
            "Epoch: 331/500, Training Loss: 1.4654, Validation Loss: 1.5126\n",
            "Epoch: 332/500, Training Loss: 1.4650, Validation Loss: 1.5131\n",
            "Epoch: 333/500, Training Loss: 1.4659, Validation Loss: 1.5094\n",
            "Epoch: 334/500, Training Loss: 1.4657, Validation Loss: 1.5130\n",
            "Epoch: 335/500, Training Loss: 1.4662, Validation Loss: 1.5076\n",
            "Epoch: 336/500, Training Loss: 1.4659, Validation Loss: 1.5109\n",
            "Epoch: 337/500, Training Loss: 1.4671, Validation Loss: 1.5092\n",
            "Epoch: 338/500, Training Loss: 1.4659, Validation Loss: 1.5094\n",
            "Epoch: 339/500, Training Loss: 1.4657, Validation Loss: 1.5085\n",
            "Epoch: 340/500, Training Loss: 1.4667, Validation Loss: 1.5133\n",
            "Epoch: 341/500, Training Loss: 1.4669, Validation Loss: 1.5126\n",
            "Epoch: 342/500, Training Loss: 1.4680, Validation Loss: 1.5084\n",
            "Epoch: 343/500, Training Loss: 1.4658, Validation Loss: 1.5124\n",
            "Epoch: 344/500, Training Loss: 1.4678, Validation Loss: 1.5124\n",
            "Epoch: 345/500, Training Loss: 1.4672, Validation Loss: 1.5101\n",
            "Epoch: 346/500, Training Loss: 1.4681, Validation Loss: 1.5121\n",
            "Epoch: 347/500, Training Loss: 1.4664, Validation Loss: 1.5125\n",
            "Epoch: 348/500, Training Loss: 1.4674, Validation Loss: 1.5146\n",
            "Epoch: 349/500, Training Loss: 1.4665, Validation Loss: 1.5126\n",
            "Epoch: 350/500, Training Loss: 1.4671, Validation Loss: 1.5103\n",
            "Epoch: 351/500, Training Loss: 1.4657, Validation Loss: 1.5081\n",
            "Epoch: 352/500, Training Loss: 1.4694, Validation Loss: 1.5127\n",
            "Epoch: 353/500, Training Loss: 1.4652, Validation Loss: 1.5090\n",
            "Epoch: 354/500, Training Loss: 1.4661, Validation Loss: 1.5079\n",
            "Epoch: 355/500, Training Loss: 1.4648, Validation Loss: 1.5136\n",
            "Epoch: 356/500, Training Loss: 1.4662, Validation Loss: 1.5097\n",
            "Epoch: 357/500, Training Loss: 1.4650, Validation Loss: 1.5073\n",
            "Epoch: 358/500, Training Loss: 1.4660, Validation Loss: 1.5100\n",
            "Epoch: 359/500, Training Loss: 1.4659, Validation Loss: 1.5098\n",
            "Epoch: 360/500, Training Loss: 1.4666, Validation Loss: 1.5083\n",
            "Epoch: 361/500, Training Loss: 1.4664, Validation Loss: 1.5106\n",
            "Epoch: 362/500, Training Loss: 1.4654, Validation Loss: 1.5105\n",
            "Epoch: 363/500, Training Loss: 1.4671, Validation Loss: 1.5111\n",
            "Epoch: 364/500, Training Loss: 1.4664, Validation Loss: 1.5122\n",
            "Epoch: 365/500, Training Loss: 1.4689, Validation Loss: 1.5082\n",
            "Epoch: 366/500, Training Loss: 1.4662, Validation Loss: 1.5051\n",
            "Epoch: 367/500, Training Loss: 1.4673, Validation Loss: 1.5098\n",
            "Epoch: 368/500, Training Loss: 1.4676, Validation Loss: 1.5122\n",
            "Epoch: 369/500, Training Loss: 1.4649, Validation Loss: 1.5115\n",
            "Epoch: 370/500, Training Loss: 1.4650, Validation Loss: 1.5114\n",
            "Epoch: 371/500, Training Loss: 1.4657, Validation Loss: 1.5094\n",
            "Epoch: 372/500, Training Loss: 1.4674, Validation Loss: 1.5093\n",
            "Epoch: 373/500, Training Loss: 1.4651, Validation Loss: 1.5125\n",
            "Epoch: 374/500, Training Loss: 1.4652, Validation Loss: 1.5091\n",
            "Epoch: 375/500, Training Loss: 1.4654, Validation Loss: 1.5100\n",
            "Epoch: 376/500, Training Loss: 1.4666, Validation Loss: 1.5094\n",
            "Epoch: 377/500, Training Loss: 1.4679, Validation Loss: 1.5093\n",
            "Epoch: 378/500, Training Loss: 1.4657, Validation Loss: 1.5125\n",
            "Epoch: 379/500, Training Loss: 1.4653, Validation Loss: 1.5116\n",
            "Epoch: 380/500, Training Loss: 1.4660, Validation Loss: 1.5118\n",
            "Epoch: 381/500, Training Loss: 1.4647, Validation Loss: 1.5077\n",
            "Epoch: 382/500, Training Loss: 1.4662, Validation Loss: 1.5089\n",
            "Epoch: 383/500, Training Loss: 1.4659, Validation Loss: 1.5125\n",
            "Epoch: 384/500, Training Loss: 1.4666, Validation Loss: 1.5083\n",
            "Epoch: 385/500, Training Loss: 1.4664, Validation Loss: 1.5124\n",
            "Epoch: 386/500, Training Loss: 1.4638, Validation Loss: 1.5139\n",
            "Epoch: 387/500, Training Loss: 1.4658, Validation Loss: 1.5077\n",
            "Epoch: 388/500, Training Loss: 1.4649, Validation Loss: 1.5113\n",
            "Epoch: 389/500, Training Loss: 1.4658, Validation Loss: 1.5050\n",
            "Epoch: 390/500, Training Loss: 1.4645, Validation Loss: 1.5093\n",
            "Epoch: 391/500, Training Loss: 1.4654, Validation Loss: 1.5074\n",
            "Epoch: 392/500, Training Loss: 1.4665, Validation Loss: 1.5094\n",
            "Epoch: 393/500, Training Loss: 1.4646, Validation Loss: 1.5113\n",
            "Epoch: 394/500, Training Loss: 1.4654, Validation Loss: 1.5099\n",
            "Epoch: 395/500, Training Loss: 1.4663, Validation Loss: 1.5090\n",
            "Epoch: 396/500, Training Loss: 1.4645, Validation Loss: 1.5079\n",
            "Epoch: 397/500, Training Loss: 1.4647, Validation Loss: 1.5108\n",
            "Epoch: 398/500, Training Loss: 1.4663, Validation Loss: 1.5092\n",
            "Epoch: 399/500, Training Loss: 1.4647, Validation Loss: 1.5127\n",
            "Epoch: 400/500, Training Loss: 1.4648, Validation Loss: 1.5053\n",
            "Epoch: 401/500, Training Loss: 1.4653, Validation Loss: 1.5063\n",
            "Epoch: 402/500, Training Loss: 1.4654, Validation Loss: 1.5117\n",
            "Epoch: 403/500, Training Loss: 1.4665, Validation Loss: 1.5114\n",
            "Epoch: 404/500, Training Loss: 1.4653, Validation Loss: 1.5121\n",
            "Epoch: 405/500, Training Loss: 1.4650, Validation Loss: 1.5096\n",
            "Epoch: 406/500, Training Loss: 1.4645, Validation Loss: 1.5104\n",
            "Epoch: 407/500, Training Loss: 1.4651, Validation Loss: 1.5097\n",
            "Epoch: 408/500, Training Loss: 1.4658, Validation Loss: 1.5110\n",
            "Epoch: 409/500, Training Loss: 1.4662, Validation Loss: 1.5064\n",
            "Epoch: 410/500, Training Loss: 1.4657, Validation Loss: 1.5087\n",
            "Epoch: 411/500, Training Loss: 1.4650, Validation Loss: 1.5098\n",
            "Epoch: 412/500, Training Loss: 1.4654, Validation Loss: 1.5088\n",
            "Epoch: 413/500, Training Loss: 1.4661, Validation Loss: 1.5062\n",
            "Epoch: 414/500, Training Loss: 1.4656, Validation Loss: 1.5078\n",
            "Epoch: 415/500, Training Loss: 1.4654, Validation Loss: 1.5058\n",
            "Epoch: 416/500, Training Loss: 1.4645, Validation Loss: 1.5113\n",
            "Epoch: 417/500, Training Loss: 1.4653, Validation Loss: 1.5059\n",
            "Epoch: 418/500, Training Loss: 1.4649, Validation Loss: 1.5076\n",
            "Epoch: 419/500, Training Loss: 1.4654, Validation Loss: 1.5100\n",
            "Epoch: 420/500, Training Loss: 1.4653, Validation Loss: 1.5079\n",
            "Epoch: 421/500, Training Loss: 1.4652, Validation Loss: 1.5083\n",
            "Epoch: 422/500, Training Loss: 1.4655, Validation Loss: 1.5076\n",
            "Epoch: 423/500, Training Loss: 1.4645, Validation Loss: 1.5097\n",
            "Epoch: 424/500, Training Loss: 1.4671, Validation Loss: 1.5099\n",
            "Epoch: 425/500, Training Loss: 1.4658, Validation Loss: 1.5073\n",
            "Epoch: 426/500, Training Loss: 1.4649, Validation Loss: 1.5059\n",
            "Epoch: 427/500, Training Loss: 1.4649, Validation Loss: 1.5083\n",
            "Epoch: 428/500, Training Loss: 1.4648, Validation Loss: 1.5087\n",
            "Epoch: 429/500, Training Loss: 1.4645, Validation Loss: 1.5059\n",
            "Epoch: 430/500, Training Loss: 1.4662, Validation Loss: 1.5103\n",
            "Epoch: 431/500, Training Loss: 1.4649, Validation Loss: 1.5122\n",
            "Epoch: 432/500, Training Loss: 1.4643, Validation Loss: 1.5111\n",
            "Epoch: 433/500, Training Loss: 1.4644, Validation Loss: 1.5091\n",
            "Epoch: 434/500, Training Loss: 1.4651, Validation Loss: 1.5071\n",
            "Epoch: 435/500, Training Loss: 1.4649, Validation Loss: 1.5083\n",
            "Epoch: 436/500, Training Loss: 1.4665, Validation Loss: 1.5067\n",
            "Epoch: 437/500, Training Loss: 1.4663, Validation Loss: 1.5057\n",
            "Epoch: 438/500, Training Loss: 1.4665, Validation Loss: 1.5061\n",
            "Epoch: 439/500, Training Loss: 1.4656, Validation Loss: 1.5077\n",
            "Epoch: 440/500, Training Loss: 1.4657, Validation Loss: 1.5049\n",
            "Epoch: 441/500, Training Loss: 1.4650, Validation Loss: 1.5103\n",
            "Epoch: 442/500, Training Loss: 1.4656, Validation Loss: 1.5055\n",
            "Epoch: 443/500, Training Loss: 1.4654, Validation Loss: 1.5092\n",
            "Epoch: 444/500, Training Loss: 1.4650, Validation Loss: 1.5020\n",
            "Epoch: 445/500, Training Loss: 1.4646, Validation Loss: 1.5070\n",
            "Epoch: 446/500, Training Loss: 1.4654, Validation Loss: 1.5104\n",
            "Epoch: 447/500, Training Loss: 1.4651, Validation Loss: 1.5076\n",
            "Epoch: 448/500, Training Loss: 1.4646, Validation Loss: 1.5064\n",
            "Epoch: 449/500, Training Loss: 1.4654, Validation Loss: 1.5059\n",
            "Epoch: 450/500, Training Loss: 1.4667, Validation Loss: 1.5055\n",
            "Epoch: 451/500, Training Loss: 1.4655, Validation Loss: 1.5076\n",
            "Epoch: 452/500, Training Loss: 1.4648, Validation Loss: 1.5073\n",
            "Epoch: 453/500, Training Loss: 1.4654, Validation Loss: 1.5084\n",
            "Epoch: 454/500, Training Loss: 1.4645, Validation Loss: 1.5097\n",
            "Epoch: 455/500, Training Loss: 1.4652, Validation Loss: 1.5038\n",
            "Epoch: 456/500, Training Loss: 1.4651, Validation Loss: 1.5076\n",
            "Epoch: 457/500, Training Loss: 1.4667, Validation Loss: 1.5041\n",
            "Epoch: 458/500, Training Loss: 1.4656, Validation Loss: 1.5061\n",
            "Epoch: 459/500, Training Loss: 1.4670, Validation Loss: 1.5079\n",
            "Epoch: 460/500, Training Loss: 1.4648, Validation Loss: 1.5095\n",
            "Epoch: 461/500, Training Loss: 1.4664, Validation Loss: 1.5083\n",
            "Epoch: 462/500, Training Loss: 1.4650, Validation Loss: 1.5082\n",
            "Epoch: 463/500, Training Loss: 1.4652, Validation Loss: 1.5089\n",
            "Epoch: 464/500, Training Loss: 1.4656, Validation Loss: 1.5070\n",
            "Epoch: 465/500, Training Loss: 1.4657, Validation Loss: 1.5054\n",
            "Epoch: 466/500, Training Loss: 1.4644, Validation Loss: 1.5100\n",
            "Epoch: 467/500, Training Loss: 1.4650, Validation Loss: 1.5041\n",
            "Epoch: 468/500, Training Loss: 1.4671, Validation Loss: 1.5090\n",
            "Epoch: 469/500, Training Loss: 1.4646, Validation Loss: 1.5100\n",
            "Epoch: 470/500, Training Loss: 1.4651, Validation Loss: 1.5056\n",
            "Epoch: 471/500, Training Loss: 1.4654, Validation Loss: 1.5099\n",
            "Epoch: 472/500, Training Loss: 1.4652, Validation Loss: 1.5078\n",
            "Epoch: 473/500, Training Loss: 1.4660, Validation Loss: 1.5090\n",
            "Epoch: 474/500, Training Loss: 1.4643, Validation Loss: 1.5072\n",
            "Epoch: 475/500, Training Loss: 1.4643, Validation Loss: 1.5088\n",
            "Epoch: 476/500, Training Loss: 1.4657, Validation Loss: 1.5099\n",
            "Epoch: 477/500, Training Loss: 1.4671, Validation Loss: 1.5113\n",
            "Epoch: 478/500, Training Loss: 1.4647, Validation Loss: 1.5064\n",
            "Epoch: 479/500, Training Loss: 1.4646, Validation Loss: 1.5055\n",
            "Epoch: 480/500, Training Loss: 1.4658, Validation Loss: 1.5079\n",
            "Epoch: 481/500, Training Loss: 1.4642, Validation Loss: 1.5075\n",
            "Epoch: 482/500, Training Loss: 1.4643, Validation Loss: 1.5083\n",
            "Epoch: 483/500, Training Loss: 1.4672, Validation Loss: 1.5048\n",
            "Epoch: 484/500, Training Loss: 1.4644, Validation Loss: 1.5068\n",
            "Epoch: 485/500, Training Loss: 1.4645, Validation Loss: 1.5086\n",
            "Epoch: 486/500, Training Loss: 1.4649, Validation Loss: 1.5060\n",
            "Epoch: 487/500, Training Loss: 1.4648, Validation Loss: 1.5040\n",
            "Epoch: 488/500, Training Loss: 1.4659, Validation Loss: 1.5099\n",
            "Epoch: 489/500, Training Loss: 1.4646, Validation Loss: 1.5096\n",
            "Epoch: 490/500, Training Loss: 1.4662, Validation Loss: 1.5060\n",
            "Epoch: 491/500, Training Loss: 1.4656, Validation Loss: 1.5087\n",
            "Epoch: 492/500, Training Loss: 1.4650, Validation Loss: 1.5121\n",
            "Epoch: 493/500, Training Loss: 1.4656, Validation Loss: 1.5072\n",
            "Epoch: 494/500, Training Loss: 1.4652, Validation Loss: 1.5094\n",
            "Epoch: 495/500, Training Loss: 1.4647, Validation Loss: 1.5075\n",
            "Epoch: 496/500, Training Loss: 1.4645, Validation Loss: 1.5062\n",
            "Epoch: 497/500, Training Loss: 1.4655, Validation Loss: 1.5086\n",
            "Epoch: 498/500, Training Loss: 1.4647, Validation Loss: 1.5077\n",
            "Epoch: 499/500, Training Loss: 1.4644, Validation Loss: 1.5068\n",
            "Epoch: 500/500, Training Loss: 1.4642, Validation Loss: 1.5064\n"
          ]
        }
      ],
      "source": [
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "loss_history = []\n",
        "val_loss_history = []\n",
        "ep_history = []\n",
        "\n",
        "steps = len(X_train_split)\n",
        "for e in range(epochs):\n",
        "    for i in range(0, steps, batch_size):\n",
        "        x_batch, y_batch = X_train_split[i:i+batch_size], y_train_split[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(x_batch)\n",
        "        loss = criteria(output, y_batch)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate training loss\n",
        "    loss_history.append(loss.item())\n",
        "    ep_history.append(e)\n",
        "\n",
        "    # Validation step\n",
        "    with torch.no_grad():\n",
        "        val_output = model(X_val)\n",
        "        val_loss = criteria(val_output, y_val)\n",
        "        val_loss_history.append(val_loss.item())\n",
        "        print(f\"Epoch: {e+1}/{epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yy_2CiOdaA6R"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fg = plt.figure()\n",
        "plt.plot(ep_history, loss_history)\n",
        "plt.plot(ep_history, val_loss_history)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Epoch and Loss vs Validation Epoch\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n0EWvoJDaA6R"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('mnist_test.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-aX3VIYaaA6S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BNf0DN7faA6S"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = test.values[:, 1:], test.values[:, 0]\n",
        "y_test = F.one_hot(torch.tensor(y_test)).to(dtype=torch.float32, device=device)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32, device=device) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DzGvTApdaA6S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 96.05%\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(len(X_test)):\n",
        "        output = model(X_test[i])\n",
        "        _, predicted = torch.max(output, 0)\n",
        "        _, actual = torch.max(y_test[i], 0)\n",
        "        total += 1\n",
        "        correct += (predicted == actual).item()\n",
        "    print(f\"Accuracy: {correct/total*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
